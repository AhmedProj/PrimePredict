{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> CODE 5 - MODEL ML INGREDIENTS</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import set_config\n",
    "from skorch import NeuralNetRegressor\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PolNum</th>\n",
       "      <th>CalYear</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Age</th>\n",
       "      <th>Group1</th>\n",
       "      <th>Bonus</th>\n",
       "      <th>Poldur</th>\n",
       "      <th>Value</th>\n",
       "      <th>Adind</th>\n",
       "      <th>SubGroup2</th>\n",
       "      <th>Group2</th>\n",
       "      <th>Density</th>\n",
       "      <th>Exppdays</th>\n",
       "      <th>Numtppd</th>\n",
       "      <th>Numtpbi</th>\n",
       "      <th>Indtppd</th>\n",
       "      <th>Indtpbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200114978</td>\n",
       "      <td>2009</td>\n",
       "      <td>Male</td>\n",
       "      <td>C</td>\n",
       "      <td>Large</td>\n",
       "      <td>Employed</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>15080</td>\n",
       "      <td>0</td>\n",
       "      <td>L46</td>\n",
       "      <td>L</td>\n",
       "      <td>72.012883</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200114994</td>\n",
       "      <td>2009</td>\n",
       "      <td>Male</td>\n",
       "      <td>E</td>\n",
       "      <td>Large</td>\n",
       "      <td>Employed</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>22370</td>\n",
       "      <td>1</td>\n",
       "      <td>O38</td>\n",
       "      <td>O</td>\n",
       "      <td>39.550411</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200115001</td>\n",
       "      <td>2009</td>\n",
       "      <td>Female</td>\n",
       "      <td>E</td>\n",
       "      <td>Large</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>39650</td>\n",
       "      <td>0</td>\n",
       "      <td>Q28</td>\n",
       "      <td>Q</td>\n",
       "      <td>169.529148</td>\n",
       "      <td>365</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200115011</td>\n",
       "      <td>2009</td>\n",
       "      <td>Female</td>\n",
       "      <td>C</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Housewife</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12600</td>\n",
       "      <td>1</td>\n",
       "      <td>L6</td>\n",
       "      <td>L</td>\n",
       "      <td>58.894688</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200115015</td>\n",
       "      <td>2009</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>Large</td>\n",
       "      <td>Employed</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>9065</td>\n",
       "      <td>0</td>\n",
       "      <td>N4</td>\n",
       "      <td>N</td>\n",
       "      <td>109.631885</td>\n",
       "      <td>365</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PolNum  CalYear  Gender Type Category  Occupation  Age  Group1  Bonus  \\\n",
       "1  200114978     2009    Male    C    Large    Employed   25      18     90   \n",
       "2  200114994     2009    Male    E    Large    Employed   20      11     30   \n",
       "3  200115001     2009  Female    E    Large  Unemployed   42      11    150   \n",
       "4  200115011     2009  Female    C   Medium   Housewife   21       5      0   \n",
       "5  200115015     2009  Female    D    Large    Employed   33      12     30   \n",
       "\n",
       "   Poldur  Value  Adind SubGroup2 Group2     Density  Exppdays  Numtppd  \\\n",
       "1       3  15080      0       L46      L   72.012883       365        1   \n",
       "2       2  22370      1       O38      O   39.550411       365        1   \n",
       "3       0  39650      0       Q28      Q  169.529148       365        2   \n",
       "4       0  12600      1        L6      L   58.894688       365        1   \n",
       "5      10   9065      0        N4      N  109.631885       365        2   \n",
       "\n",
       "   Numtpbi  Indtppd  Indtpbi  \n",
       "1        0      0.0      0.0  \n",
       "2        0      0.0      0.0  \n",
       "3        0      0.0      0.0  \n",
       "4        0      0.0      0.0  \n",
       "5        0      0.0      0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original = pd.read_csv('training.csv', sep=';')\n",
    "data_original.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating wrong values\n",
    "polnums = []\n",
    "for i, v in data_original[\"PolNum\"].value_counts().items():\n",
    "    if v == 2:\n",
    "        polnums.append(i)\n",
    "ttt = data_original[data_original[\"PolNum\"].apply(lambda x: True if x in polnums else False)]\n",
    "\n",
    "def idx_lowest(dff):\n",
    "    # Group by the first column and find the index of the minimum value in the third column\n",
    "    df = dff.copy()\n",
    "    df[\"total_cost\"] = df[\"Indtppd\"] + df[\"Indtpbi\"]\n",
    "    idx_to_drop = df.groupby(df.columns[0])[df.columns[-1]].idxmin()\n",
    "    return idx_to_drop\n",
    "\n",
    "data_original.drop(idx_lowest(ttt), inplace=True)\n",
    "#data_original[\"PolNum\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50000 entries, 22 to 50021\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Gender      50000 non-null  object \n",
      " 1   Type        50000 non-null  object \n",
      " 2   Occupation  50000 non-null  object \n",
      " 3   Age         50000 non-null  int64  \n",
      " 4   Group1      50000 non-null  int64  \n",
      " 5   Bonus       50000 non-null  int64  \n",
      " 6   Poldur      50000 non-null  int64  \n",
      " 7   Value       50000 non-null  int64  \n",
      " 8   Adind       50000 non-null  int64  \n",
      " 9   Group2      50000 non-null  object \n",
      " 10  Density     50000 non-null  float64\n",
      " 11  Exppdays    50000 non-null  int64  \n",
      " 12  Numtppd     50000 non-null  int64  \n",
      " 13  Numtpbi     50000 non-null  int64  \n",
      " 14  Indtppd     50000 non-null  float64\n",
      " 15  Indtpbi     50000 non-null  float64\n",
      "dtypes: float64(3), int64(9), object(4)\n",
      "memory usage: 6.5+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193387/2101252524.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop(cols_to_drop, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Selecting one particular year\n",
    "data = data_original[data_original[\"CalYear\"] == 2009]\n",
    "cols_to_drop = ['PolNum', 'CalYear', 'SubGroup2', 'Category']\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Group1</th>\n",
       "      <th>Bonus</th>\n",
       "      <th>Poldur</th>\n",
       "      <th>Value</th>\n",
       "      <th>Adind</th>\n",
       "      <th>Density</th>\n",
       "      <th>Exppdays</th>\n",
       "      <th>Numtppd</th>\n",
       "      <th>Numtpbi</th>\n",
       "      <th>Indtppd</th>\n",
       "      <th>Indtpbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.101560</td>\n",
       "      <td>10.675800</td>\n",
       "      <td>-6.695000</td>\n",
       "      <td>5.482760</td>\n",
       "      <td>16495.133200</td>\n",
       "      <td>0.511360</td>\n",
       "      <td>116.458351</td>\n",
       "      <td>327.649540</td>\n",
       "      <td>0.139960</td>\n",
       "      <td>0.046780</td>\n",
       "      <td>98.585283</td>\n",
       "      <td>208.42643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.307887</td>\n",
       "      <td>4.679553</td>\n",
       "      <td>48.816786</td>\n",
       "      <td>4.595224</td>\n",
       "      <td>10528.285772</td>\n",
       "      <td>0.499876</td>\n",
       "      <td>79.190922</td>\n",
       "      <td>73.603182</td>\n",
       "      <td>0.421206</td>\n",
       "      <td>0.219983</td>\n",
       "      <td>422.853097</td>\n",
       "      <td>1761.53048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.377142</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8395.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.566406</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14652.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.382351</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>22595.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>171.372936</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>49990.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>297.385170</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10955.476251</td>\n",
       "      <td>60914.68741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age        Group1         Bonus        Poldur         Value  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean      41.101560     10.675800     -6.695000      5.482760  16495.133200   \n",
       "std       14.307887      4.679553     48.816786      4.595224  10528.285772   \n",
       "min       18.000000      1.000000    -50.000000      0.000000   1000.000000   \n",
       "25%       30.000000      7.000000    -40.000000      1.000000   8395.000000   \n",
       "50%       40.000000     11.000000    -30.000000      4.000000  14652.500000   \n",
       "75%       51.000000     14.000000     10.000000      9.000000  22595.000000   \n",
       "max       75.000000     20.000000    150.000000     15.000000  49990.000000   \n",
       "\n",
       "              Adind       Density      Exppdays       Numtppd       Numtpbi  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       0.511360    116.458351    327.649540      0.139960      0.046780   \n",
       "std        0.499876     79.190922     73.603182      0.421206      0.219983   \n",
       "min        0.000000     14.377142     91.000000      0.000000      0.000000   \n",
       "25%        0.000000     50.566406    340.000000      0.000000      0.000000   \n",
       "50%        1.000000     93.382351    365.000000      0.000000      0.000000   \n",
       "75%        1.000000    171.372936    365.000000      0.000000      0.000000   \n",
       "max        1.000000    297.385170    365.000000      7.000000      3.000000   \n",
       "\n",
       "            Indtppd      Indtpbi  \n",
       "count  50000.000000  50000.00000  \n",
       "mean      98.585283    208.42643  \n",
       "std      422.853097   1761.53048  \n",
       "min        0.000000      0.00000  \n",
       "25%        0.000000      0.00000  \n",
       "50%        0.000000      0.00000  \n",
       "75%        0.000000      0.00000  \n",
       "max    10955.476251  60914.68741  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193387/1575416020.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"total_cost\"] = np.log1p(data[\"Indtppd\"] + data[\"Indtpbi\"])\n",
      "/tmp/ipykernel_193387/1575416020.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"frequence_claims\"] = data[\"Numtppd\"] + data[\"Numtpbi\"]\n",
      "/tmp/ipykernel_193387/1575416020.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Exppdays\"] = data[\"Exppdays\"] / 365\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering\n",
    "data[\"total_cost\"] = np.log1p(data[\"Indtppd\"] + data[\"Indtpbi\"])\n",
    "data[\"frequence_claims\"] = data[\"Numtppd\"] + data[\"Numtpbi\"]\n",
    "data[\"Exppdays\"] = data[\"Exppdays\"] / 365\n",
    "\n",
    "# Removing already encoded features\n",
    "df = data.copy()\n",
    "cols_to_drop2 = [\"Numtppd\",\t\"Numtpbi\", \"Indtppd\", \"Indtpbi\", \"Group2\", \"Gender\"]\n",
    "df.drop(cols_to_drop2, axis=1, inplace=True)\n",
    "\n",
    "# Removing outliers\n",
    "percentile_cost = np.percentile(data[\"total_cost\"], 98)\n",
    "percentile_freq = np.percentile(data[\"frequence_claims\"], 99)\n",
    "df = df[(df[\"total_cost\"] < percentile_cost) & (df[\"frequence_claims\"] < percentile_freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Type', 'Occupation', 'Age', 'Group1', 'Bonus', 'Poldur', 'Value',\n",
      "       'Adind', 'Density', 'Exppdays', 'total_cost', 'frequence_claims'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "frequence_claims\n",
       "0    42294\n",
       "1     5751\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The problem is now binary\n",
    "print(df.columns)\n",
    "df[\"frequence_claims\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(x, y, values=[1], new_sizes=[0]):\n",
    "    \"\"\"\n",
    "    This function performs oversampling or undersampling,\n",
    "    depending on the class size and the requested new_size\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    x: DataFrame\n",
    "       Dataframe containing the features\n",
    "    y: Series\n",
    "       1D array with axis labels that contains the different classes\n",
    "    values: List of integers    \n",
    "            It contains the class values required to resample \n",
    "    new_sizes: List of integers\n",
    "               size required for the corresponding class in values\n",
    "    OUTPUT\n",
    "    ------\n",
    "    x_result: DataFrame\n",
    "              Resampled dataframe containing the features\n",
    "    y_result: Series\n",
    "              Resampled series object containing the different classes\n",
    "    \"\"\"\n",
    "\n",
    "    x['target'] = y\n",
    "    for val, size in zip(values, new_sizes):\n",
    "        df_sampled = x[x['target'] == val]\n",
    "        n_lines = df_sampled.shape[0]\n",
    "        # Over_sampling\n",
    "        if n_lines <= size:\n",
    "            rdn_rows = random.choices(range(0, n_lines), k=size - df_sampled.shape[0])\n",
    "            x = pd.concat([x, df_sampled.iloc[rdn_rows]], ignore_index=True)\n",
    "        # Under_sampling    \n",
    "        else:    \n",
    "            rdn_rows = random.sample(list(df_sampled.index), k=df_sampled.shape[0] - size)\n",
    "            x = x.drop(rdn_rows)\n",
    "\n",
    "    x_result = x.drop('target', axis=1)\n",
    "    y_result = x['target']   \n",
    "    \n",
    "    return x_result, y_result\n",
    "\n",
    "# Defining a selector to get the categorical and numerical variables \n",
    "categorical_selector = selector(dtype_include = object)\n",
    "numerical_selector = selector(dtype_exclude=object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value ----->0.17079641924469724\n",
      "Density ----->0.1706789779551798\n",
      "Age ----->0.1335943715457432\n",
      "Bonus ----->0.11143591314378308\n",
      "Group1 ----->0.10285737604649824\n",
      "Poldur ----->0.09816428053939621\n",
      "Exppdays ----->0.05374331357322445\n",
      "Adind ----->0.020003519365901137\n",
      "Type_A ----->0.016621656771068378\n",
      "Type_D ----->0.015406859470082633\n",
      "Type_B ----->0.015346275510049783\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([\"total_cost\", \"frequence_claims\"], axis=1)\n",
    "y = df[\"frequence_claims\"]\n",
    "\n",
    "cat_variables = categorical_selector(X)\n",
    "num_variables = numerical_selector(X)\n",
    "\n",
    "X = pd.get_dummies(X, columns=cat_variables) * 1\n",
    "\n",
    "# Create a random forest classifier object\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rfc.fit(X, y)\n",
    "\n",
    "# Get feature importances from the trained model\n",
    "importances = rfc.feature_importances_\n",
    "\n",
    "# Sort the feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Select the features that sum up to 90%\n",
    "X_columns = X.columns\n",
    "suma = 0\n",
    "for i in indices:\n",
    "    print(X_columns[i] , '----->' + str(importances[i]))\n",
    "    suma += importances[i]\n",
    "    if suma >= 0.9:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling\n",
    "X = df.drop([\"total_cost\", \"frequence_claims\"], axis=1)\n",
    "y = df[\"frequence_claims\"]\n",
    "\n",
    "cat_variables = categorical_selector(X)\n",
    "num_variables = numerical_selector(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0) \n",
    "\n",
    "# resampling the data\n",
    "X_train, y_train = random_sampling(X_train, y_train, values=[0, 1], new_sizes=[10000, 10000])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68      1985\n",
      "           1       0.69      0.69      0.69      2015\n",
      "\n",
      "    accuracy                           0.69      4000\n",
      "   macro avg       0.69      0.69      0.69      4000\n",
      "weighted avg       0.69      0.69      0.69      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1, 10],           \n",
    "    'model__gamma': ['scale', 'auto'],  \n",
    "    \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=freq_pipeline,   \n",
    "    param_grid=param_grid,     \n",
    "    scoring='accuracy',       \n",
    "    cv=5,                      \n",
    "    verbose=1,                 \n",
    "    n_jobs=-1                  \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "model1 = grid_search.best_estimator_\n",
    "\n",
    "predictions = model1.predict(X_val)\n",
    "\n",
    "score = classification_report(y_val, predictions)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.66      0.77      8459\n",
      "           1       0.21      0.68      0.32      1150\n",
      "\n",
      "    accuracy                           0.66      9609\n",
      "   macro avg       0.58      0.67      0.55      9609\n",
      "weighted avg       0.85      0.66      0.72      9609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing with data without resampling (original distribution)\n",
    "prediction_test = model1.predict(X_test)\n",
    "score = classification_report(y_test, prediction_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Meilleurs paramètres (RF): {'model__max_depth': 5, 'model__n_estimators': 100, 'model__random_state': 0}\n",
      "Meilleur score (MSE) (RF): 1.957733633402801\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "class NNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NNetwork, self).__init__()\n",
    "        \n",
    "        self.module = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        self.double()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.module(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    NNetwork(X_train2.shape[1]),\n",
    "    criterion=nn.MSELoss,\n",
    "    max_epochs=EPOCHS,\n",
    "    optimizer=optim.Adam,\n",
    "    optimizer__lr = 0.0001\n",
    ")\n",
    "\n",
    "param_grid_rf = {\n",
    "    'model__n_estimators': [50, 100, 150],\n",
    "    'model__max_depth': [5, 7, 10],\n",
    "    'model__random_state': [0]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=nn_pipeline,   \n",
    "    param_grid=param_grid_rf,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train2, y_train2)\n",
    "\n",
    "print(\"Meilleurs paramètres (RF):\", grid_search_rf.best_params_)\n",
    "print(\"Meilleur score (MSE) (RF):\", -grid_search_rf.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9752309890639455"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "predict = grid_search_rf.predict(X_test2)\n",
    "mse = mean_squared_error(y_test2, predict)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average prime is: 86.7633105417968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ensemble_model.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop([\"total_cost\", \"frequence_claims\"], axis=1)\n",
    "y = df[\"frequence_claims\"]\n",
    "\n",
    "cat_variables = categorical_selector(X)\n",
    "num_variables = numerical_selector(X)\n",
    "\n",
    "prime_avg = sum(np.expm1(df['total_cost'])) / len(df['total_cost'])\n",
    "print(\"The average prime is: \" + str(prime_avg)) \n",
    "\n",
    "class ModelEnsemble(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" \n",
    "    With this class we can estimate the prime value for a given client.\n",
    "    We first calculate the frequency of accidents, then we proceed to calculate the prime.\n",
    "    This class is not trainable, it receives models that have been already trained\n",
    "    \"\"\"\n",
    "    def __init__(self, model1, model2, prime_avg=86.76, n0=42294, n1=5751):\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.prime_avg = prime_avg\n",
    "        self.n0 = n0\n",
    "        self.n1 = n1\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.to_frame(0).T\n",
    "        model1_output = self.model1.predict(X)\n",
    "\n",
    "        if model1_output == 0:\n",
    "            prime = self.prime_avg\n",
    "        else:\n",
    "            X[\"frequence_claims\"] = model1_output\n",
    "            prime = self.prime_avg + self.n1 * np.expm1(self.model2.predict(X)[0]) / self.n0\n",
    "        return prime\n",
    "    \n",
    "\n",
    "ensemble_model = ModelEnsemble(grid_search, grid_search_rf)\n",
    "\n",
    "# Saving the model\n",
    "joblib.dump(ensemble_model, 'ensemble_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prime for this client is: 86.76\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_data = df.drop([\"total_cost\", \"frequence_claims\"], axis=1)\n",
    "n = random.randint(0, test_data.shape[0])\n",
    "test_df = test_data.iloc[n]\n",
    "\n",
    "prediction = ensemble_model.transform(test_df)\n",
    "print(\"The prime for this client is: %5.2f\" % prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.76"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the saved model\n",
    "model_load = joblib.load('ensemble_model.joblib')\n",
    "model_load.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
